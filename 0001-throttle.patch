From 21598e3fd48d4ffdc65c3403701a3cb9d5f79b98 Mon Sep 17 00:00:00 2001
From: Clarence Ng <clarence.wyng@gmail.com>
Date: Thu, 18 Aug 2022 05:06:09 -0700
Subject: [PATCH] throttle

Signed-off-by: Clarence Ng <clarence.wyng@gmail.com>
---
 python/ray/tests/test_memory_pressure.py | 33 +++++++++++++++++++++++-
 src/ray/common/memory_monitor.cc         | 13 +++++++++-
 src/ray/common/memory_monitor.h          | 17 ++++++++++++
 src/ray/common/ray_config_def.h          | 15 +++++++++++
 src/ray/raylet/local_task_manager.cc     | 21 +++++++++++++++
 src/ray/raylet/local_task_manager.h      |  5 ++++
 src/ray/raylet/node_manager.cc           | 21 +++++++++++++++
 7 files changed, 123 insertions(+), 2 deletions(-)

diff --git a/python/ray/tests/test_memory_pressure.py b/python/ray/tests/test_memory_pressure.py
index 37c1b58e3..acecb9cce 100644
--- a/python/ray/tests/test_memory_pressure.py
+++ b/python/ray/tests/test_memory_pressure.py
@@ -19,12 +19,14 @@ def ray_with_memory_monitor(shutdown_only):
     metrics_report_interval_ms = 100
 
     with ray.init(
-        num_cpus=1,
         object_store_memory=100 * 1024 * 1024,
         _system_config={
             "memory_usage_threshold_fraction": memory_usage_threshold_fraction,
             "memory_monitor_interval_ms": memory_monitor_interval_ms,
             "metrics_report_interval_ms": metrics_report_interval_ms,
+            "low_memory_threshold_for_task_dispatch_throttling": 0.5,
+            "low_memory_task_dispatch_token_refresh_interval_ms": 1000,
+            "low_memory_task_dispatch_token_refresh_count": 1,
         },
     ):
         yield
@@ -204,6 +206,35 @@ def test_worker_dump(ray_with_memory_monitor):
             oom_actor.allocate.remote(bytes_to_alloc, memory_monitor_interval_ms * 3)
         )
 
+@pytest.mark.skipif(
+    sys.platform != "linux" and sys.platform != "linux2",
+    reason="memory monitor only on linux currently",
+)
+def test_backpressure(ray_with_memory_monitor):
+    # memory_users = [Leaker.options(name=str(i)).remote() for i in range(7)]
+    hogger = Leaker.options(name="memory_hogger").remote()
+    bytes_to_alloc = get_additional_bytes_to_reach_memory_usage_pct(memory_usage_threshold_fraction - 0.1)
+    ray.get(
+            hogger.allocate.remote(bytes_to_alloc)
+        )
+
+    for _ in range(10):
+        refs = [no_retry.remote(0) for _ in range(10)]
+        # refs = [user.allocate.remote(0) for user in memory_users]
+        _ = [ray.get(ref) for ref in refs]
+
+    bytes_to_alloc = get_additional_bytes_to_reach_memory_usage_pct(memory_usage_threshold_fraction + 0.2)
+    with pytest.raises(ray.exceptions.RayActorError) as _:
+      ray.get(
+              hogger.allocate.remote(bytes_to_alloc, memory_monitor_interval_ms * 10)
+          )
+
+    while True:
+        refs = [no_retry.remote(0) for _ in range(10)]
+        # refs = [user.allocate.remote(0) for user in memory_users]
+        _ = [ray.get(ref) for ref in refs]
+
+    # time.sleep(1000)
 
 if __name__ == "__main__":
     sys.exit(pytest.main(["-sv", __file__]))
diff --git a/src/ray/common/memory_monitor.cc b/src/ray/common/memory_monitor.cc
index aeb66fe5c..02dd10fe3 100644
--- a/src/ray/common/memory_monitor.cc
+++ b/src/ray/common/memory_monitor.cc
@@ -33,7 +33,8 @@ MemoryMonitor::MemoryMonitor(float usage_threshold,
         boost::asio::io_service::work io_service_work_(io_context_);
         io_context_.run();
       }),
-      runner_(io_context_) {
+      runner_(io_context_),
+      memory_info_(-1,-1) {
   RAY_CHECK(monitor_callback_ != nullptr);
   RAY_CHECK_GE(usage_threshold_, 0);
   RAY_CHECK_LE(usage_threshold_, 1);
@@ -76,6 +77,12 @@ bool MemoryMonitor::IsUsageAboveThreshold() {
   return is_usage_above_threshold;
 }
 
+std::tuple<int64_t, int64_t> MemoryMonitor::GetMemoryBytesCached() {
+  absl::ReaderMutexLock lock(&memory_info_mutex_);
+  auto memory_info = memory_info_;
+  return std::tuple(memory_info.used_bytes, memory_info.total_bytes);
+}
+
 std::tuple<int64_t, int64_t> MemoryMonitor::GetMemoryBytes() {
   auto [cgroup_used_bytes, cgroup_total_bytes] = GetCGroupMemoryBytes();
 #ifndef __linux__
@@ -90,6 +97,10 @@ std::tuple<int64_t, int64_t> MemoryMonitor::GetMemoryBytes() {
   if (system_total_bytes == cgroup_total_bytes) {
     system_used_bytes = cgroup_used_bytes;
   }
+  {
+    absl::WriterMutexLock lock(&memory_info_mutex_);
+    memory_info_ = MemoryInfo(system_used_bytes, system_total_bytes);
+  }
   return std::tuple(system_used_bytes, system_total_bytes);
 }
 
diff --git a/src/ray/common/memory_monitor.h b/src/ray/common/memory_monitor.h
index 76b885619..c724125ed 100644
--- a/src/ray/common/memory_monitor.h
+++ b/src/ray/common/memory_monitor.h
@@ -16,6 +16,7 @@
 
 #include <gtest/gtest_prod.h>
 
+#include "absl/synchronization/mutex.h"
 #include "ray/common/asio/instrumented_io_context.h"
 #include "ray/common/asio/periodical_runner.h"
 
@@ -26,6 +27,16 @@ namespace ray {
 /// threshold at this instant.
 using MemoryUsageRefreshCallback = std::function<void(bool is_usage_above_threshold)>;
 
+/// Captures the memory information of a particular entity,
+/// Whether it being a process or the node.
+struct MemoryInfo {
+    MemoryInfo(int64_t memory_used, int64_t memory_total)
+        : used_bytes(memory_used),
+          total_bytes(memory_total) {}
+    int64_t used_bytes;
+    int64_t total_bytes;
+};
+
 /// Monitors the memory usage of the node.
 /// It checks the memory usage p
 /// This class is thread safe.
@@ -49,6 +60,9 @@ class MemoryMonitor {
   /// \return the used memory in bytes for the process
   int64_t GetProcessMemoryBytes(int64_t process_id);
 
+  /// \return the used and total memory in bytes.
+  std::tuple<int64_t, int64_t> GetMemoryBytesCached();
+
  private:
   static constexpr char kCgroupsV1MemoryMaxPath[] =
       "/sys/fs/cgroup/memory/memory.limit_in_bytes";
@@ -94,6 +108,9 @@ class MemoryMonitor {
   instrumented_io_context io_context_;
   std::thread monitor_thread_;
   PeriodicalRunner runner_;
+
+  MemoryInfo memory_info_ GUARDED_BY(memory_info_mutex_);
+  mutable absl::Mutex memory_info_mutex_;
 };
 
 }  // namespace ray
diff --git a/src/ray/common/ray_config_def.h b/src/ray/common/ray_config_def.h
index 0ce2a195e..9588a11e2 100644
--- a/src/ray/common/ray_config_def.h
+++ b/src/ray/common/ray_config_def.h
@@ -84,6 +84,21 @@ RAY_CONFIG(float, memory_usage_threshold_fraction, 0.9)
 /// Monitor is disabled when this value is 0.
 RAY_CONFIG(uint64_t, memory_monitor_interval_ms, 0)
 
+RAY_CONFIG(float, critical_low_memory_threshold_for_task_dispatch_throttling, 0)
+
+/// The interval for refreshing task token, that is
+/// used to throttle the number tasks that can be dispatched.
+/// Setting this to zero disables this. Only runs on low memory
+RAY_CONFIG(uint64_t, critical_low_memory_task_dispatch_token_refresh_interval_ms, 0)
+
+/// The number of task dispatch tokens to set per interval.
+/// The number of tokens available at any time will never exceed this value.
+RAY_CONFIG(uint64_t, critical_low_memory_task_dispatch_token_refresh_count, 0)
+
+RAY_CONFIG(float, low_memory_threshold_for_task_dispatch_throttling, 0)
+RAY_CONFIG(uint64_t, low_memory_task_dispatch_token_refresh_interval_ms, 0)
+RAY_CONFIG(int64_t, low_memory_task_dispatch_token_refresh_count, 0)
+
 /// If the raylet fails to get agent info, we will retry after this interval.
 RAY_CONFIG(uint64_t, raylet_get_agent_info_interval_ms, 1)
 
diff --git a/src/ray/raylet/local_task_manager.cc b/src/ray/raylet/local_task_manager.cc
index a2edff1ef..e6b9c0a5b 100644
--- a/src/ray/raylet/local_task_manager.cc
+++ b/src/ray/raylet/local_task_manager.cc
@@ -122,6 +122,14 @@ void LocalTaskManager::DispatchScheduledTasksToWorkers() {
     /// with nested tasks.
     bool is_infeasible = false;
     for (auto work_it = dispatch_queue.begin(); work_it != dispatch_queue.end();) {
+      auto tokens = task_dispatch_tokens_.load();
+      if (tokens >= 0) {
+        RAY_LOG(WARNING) << "tokens for dispatching!" << tokens;
+        if (tokens == 0) {
+          return;
+        }
+      }
+
       auto &work = *work_it;
       const auto &task = work->task;
       const auto spec = task.GetTaskSpecification();
@@ -136,6 +144,9 @@ void LocalTaskManager::DispatchScheduledTasksToWorkers() {
           sched_cls_info.running_tasks.size() >= sched_cls_info.capacity &&
           work->GetState() == internal::WorkStatus::WAITING) {
         RAY_LOG(DEBUG) << "Hit cap! time=" << get_time_ms_()
+                       << " scheduling class=" << TaskSpecification::GetSchedulingClassDescriptor(scheduling_class).DebugString()
+                       << " scheduling class capacity=" << sched_cls_info.capacity
+                       << " scheduling class running=" << sched_cls_info.running_tasks.size()
                        << " next update time=" << sched_cls_info.next_update_time;
         if (get_time_ms_() < sched_cls_info.next_update_time) {
           // We're over capacity and it's not time to admit a new task yet.
@@ -251,6 +262,11 @@ void LocalTaskManager::DispatchScheduledTasksToWorkers() {
         work->SetStateWaitingForWorker();
         bool is_detached_actor = spec.IsDetachedActor();
         auto &owner_address = spec.CallerAddress();
+        if (task_dispatch_tokens_.load() > 0) {
+          task_dispatch_tokens_.fetch_sub(1);
+          RAY_LOG(WARNING) << "subtracting one token now at " << task_dispatch_tokens_.load();
+        }
+        
         /// TODO(scv119): if a worker is not started, the resources is leaked and
         // task might be hanging.
         worker_pool_.PopWorker(
@@ -714,6 +730,11 @@ void LocalTaskManager::ReleaseTaskArgs(const TaskID &task_id) {
   }
 }
 
+void LocalTaskManager::SetTaskTokens(int32_t tokens) {
+  task_dispatch_tokens_ = tokens;
+}
+
+
 namespace {
 void ReplyCancelled(std::shared_ptr<internal::Work> &work,
                     rpc::RequestWorkerLeaseReply::SchedulingFailureType failure_type,
diff --git a/src/ray/raylet/local_task_manager.h b/src/ray/raylet/local_task_manager.h
index ed2454592..b225d56f5 100644
--- a/src/ray/raylet/local_task_manager.h
+++ b/src/ray/raylet/local_task_manager.h
@@ -188,6 +188,9 @@ class LocalTaskManager : public ILocalTaskManager {
     return num_unschedulable_task_spilled_;
   }
 
+  void SetTaskTokens(int32_t tokens);
+
+
  private:
   struct SchedulingClassInfo;
 
@@ -383,6 +386,8 @@ class LocalTaskManager : public ILocalTaskManager {
   size_t num_waiting_task_spilled_ = 0;
   size_t num_unschedulable_task_spilled_ = 0;
 
+  std::atomic<int32_t> task_dispatch_tokens_ = -1;
+
   friend class SchedulerResourceReporter;
   friend class ClusterTaskManagerTest;
   friend class SchedulerStats;
diff --git a/src/ray/raylet/node_manager.cc b/src/ray/raylet/node_manager.cc
index 765132053..1948faf49 100644
--- a/src/ray/raylet/node_manager.cc
+++ b/src/ray/raylet/node_manager.cc
@@ -565,6 +565,27 @@ ray::Status NodeManager::RegisterGcs() {
         RayConfig::instance().raylet_check_gc_period_milliseconds(),
         "NodeManager.CheckGC");
   }
+  if (RayConfig::instance().low_memory_task_dispatch_token_refresh_interval_ms() > 0 &&
+    RayConfig::instance().low_memory_threshold_for_task_dispatch_throttling() > 0) {
+    periodical_runner_.RunFnPeriodically(
+        [this] { 
+          auto [used_memory_bytes, total_memory_bytes] = memory_monitor_->GetMemoryBytesCached();
+          RAY_LOG(INFO) << "low_memory_task_dispatch_token_refresh" << used_memory_bytes << " " << total_memory_bytes << " setting token " << RayConfig::instance().low_memory_task_dispatch_token_refresh_count();
+          if (total_memory_bytes == -1 || used_memory_bytes == -1) {
+            return;
+          }
+          auto usage_fraction = static_cast<float>(used_memory_bytes) / total_memory_bytes;
+          bool is_usage_above_threshold = usage_fraction > RayConfig::instance().low_memory_threshold_for_task_dispatch_throttling();
+          if (is_usage_above_threshold) {
+            auto tokens = RayConfig::instance().low_memory_task_dispatch_token_refresh_count();
+            local_task_manager_->SetTaskTokens(tokens);
+          } else {
+            local_task_manager_->SetTaskTokens(-1);
+          }
+        },
+        RayConfig::instance().low_memory_task_dispatch_token_refresh_interval_ms(),
+        "NodeManager.low_memory_task_dispatch_token_refresh");
+  }
   return ray::Status::OK();
 }
 
-- 
2.25.1

